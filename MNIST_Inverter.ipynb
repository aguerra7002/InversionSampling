{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b6cd2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need this for matrix multiplication to work for some reason lol\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "288e33a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import save_image\n",
    "from vae import VAE\n",
    "import numpy as np\n",
    "from scipy.linalg import svd, null_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb70e3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc31): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (fc32): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (fc4): Linear(in_features=2, out_features=256, bias=True)\n",
       "  (fc5): Linear(in_features=256, out_features=512, bias=True)\n",
       "  (fc6): Linear(in_features=512, out_features=784, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae = torch.load(\"vae.model\")\n",
    "vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64ac31e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights shape (512, 784) (256, 512) (2, 256)\n",
      "Biases shape (512,) (256,) (2,)\n"
     ]
    }
   ],
   "source": [
    "# Get all the weight/bias matrices.\n",
    "w1 = vae.fc1.weight.cpu().detach().numpy()\n",
    "b1 = vae.fc1.bias.cpu().detach().numpy()\n",
    "w2 = vae.fc2.weight.cpu().detach().numpy()\n",
    "b2 = vae.fc2.bias.cpu().detach().numpy()\n",
    "w3 = vae.fc31.weight.cpu().detach().numpy()\n",
    "b3 = vae.fc31.bias.cpu().detach().numpy()\n",
    "\n",
    "print(\"Weights shape\", w1.shape, w2.shape, w3.shape)\n",
    "print(\"Biases shape\", b1.shape, b2.shape, b3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7d27d9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_leaky_relu_(scalar, slope=0.1):\n",
    "    \"\"\"\n",
    "    Inverts a leaky relu transformation\n",
    "    \"\"\"\n",
    "    return scalar if scalar >= 0 else scalar / slope\n",
    "\n",
    "\n",
    "def sample_preimage(W, b, z, n, noise_level=0.001, as_list=False):\n",
    "    \"\"\"\n",
    "    Finds n points x_1, ..., x_n such that W x_i + b = z for all i\n",
    "    \"\"\"\n",
    "    # Subtract b from eq\n",
    "    new_b = z-b\n",
    "    # Compute pseudoinverse\n",
    "    pinv = np.linalg.pinv(W)\n",
    "    # Get the \"central\" x which solves the equation (i.e., no null space vectors)\n",
    "    x_orig = pinv @ new_b\n",
    "    # Compute the null_space of W (transpose to get right orientation)\n",
    "    ns = null_space(W).T\n",
    "    # Compute some Gaussian noise, and then scale by noise_level\n",
    "    noise = np.random.randn(n, ns.shape[0]) * noise_level\n",
    "    # Noise_null_space matrix\n",
    "    noise_null_mat = noise @ ns\n",
    "    # Setup the array where our samples will live in\n",
    "    new_points = np.empty((n, x_orig.shape[0]))\n",
    "    # Generate our samples\n",
    "    for i in range(n):\n",
    "        new_points[i] = x_orig + noise_null_mat[i]\n",
    "        \n",
    "    # Check that our sampled points are actually correct\n",
    "    #assert np.allclose((new_points @ W.T) + b, np.repeat(np.expand_dims(z, 0), n, axis=0))\n",
    "    \n",
    "    # Return the original x, as well as the sampled points\n",
    "    if as_list:\n",
    "        return x_orig, list(new_points)\n",
    "    else:\n",
    "        return x_orig, new_points\n",
    "\n",
    "# Create the vectorized version of inverse_leaky_relu\n",
    "invert_leaky_relu = np.vectorize(invert_leaky_relu_)\n",
    "\n",
    "def generate_preimage_points(z1, w1, w2, w3, b1, b2, b3, n_splits=3):\n",
    "#     assert(len(w_tup) == len(b_tup))\n",
    "    \n",
    "#     s_final = np.empty((n_splits ** len(w_tup), ))\n",
    "#     for i in range(len(w_tup)):\n",
    "#         for n in range(n_splits ** i):\n",
    "#             _, s = sample_preimage(w_tup[-(i+1)], b_tup[-(i+1)], z1, n_splits)\n",
    "#             s1 = invert_leaky_relu(s)\n",
    "#             print()\n",
    "    \n",
    "    # Generate first set of preimage points\n",
    "    _, s1 = sample_preimage(w3, b3, z1, n_splits)\n",
    "    # Invert leaky relu and convert to list\n",
    "    s1 = list(invert_leaky_relu(s1))\n",
    "\n",
    "    # Generate second set of preimage points\n",
    "    s2 = np.empty((n_splits * n_splits, w2.shape[1]))\n",
    "    for i, z1 in enumerate(s1):\n",
    "        _, s2_single = sample_preimage(w2, b2, z1, n_splits)\n",
    "        # Fill in our samples\n",
    "        s2[n_splits*i:n_splits*(i+1)] = s2_single\n",
    "    # Invert leaky relu and convert to list\n",
    "    s2 = list(invert_leaky_relu(s2))\n",
    "    \n",
    "    # Generate 3rd set of preimage points\n",
    "    s3 = np.empty((n_splits ** 3, w1.shape[1]))\n",
    "    for i, z2 in enumerate(s2):\n",
    "        _, s3_single = sample_preimage(w1, b1, z2, n_splits)\n",
    "        s3[n_splits*i:n_splits*(i+1)] = s3_single\n",
    "    \n",
    "    # We have our preimage points, so we can return.\n",
    "    return s3.reshape((s3.shape[0], 1, 28, 28))\n",
    "    \n",
    "def generate_preimage_points_2(z1, w1, w2, b1, b2, n_splits=3, h1=None):\n",
    "#     assert(len(w_tup) == len(b_tup))\n",
    "    \n",
    "#     s_final = np.empty((n_splits ** len(w_tup), ))\n",
    "#     for i in range(len(w_tup)):\n",
    "#         for n in range(n_splits ** i):\n",
    "#             _, s = sample_preimage(w_tup[-(i+1)], b_tup[-(i+1)], z1, n_splits)\n",
    "#             s1 = invert_leaky_relu(s)\n",
    "#             print()\n",
    "    # For the second one, invert leaky_relu\n",
    "    \n",
    "    z1 = invert_leaky_relu(z1)\n",
    "    # Generate first set of preimage points\n",
    "    orig, s1 = sample_preimage(w2, b2, z1, n_splits)\n",
    "    if h1 is not None:\n",
    "        print(np.linalg.norm(orig - h1))\n",
    "    # Invert leaky relu and convert to list\n",
    "    s1 = list(invert_leaky_relu(s1))\n",
    "\n",
    "    # Generate second set of preimage points\n",
    "    s2 = np.empty((n_splits ** 2, w1.shape[1]))\n",
    "    for i, z1 in enumerate(s1):\n",
    "        _, s2_single = sample_preimage(w1, b1, z1, n_splits)\n",
    "        # Fill in our samples\n",
    "        s2[n_splits*i:n_splits*(i+1)] = s2_single\n",
    "    # Invert leaky relu and convert to list\n",
    "#     s2 = list(invert_leaky_relu(s2))\n",
    "    \n",
    "    # We have our preimage points, so we can return.\n",
    "    return s2.reshape((s2.shape[0], 1, 28, 28))\n",
    "\n",
    "def generate_preimage_points_3(z1, w1, b1, n_splits=3):\n",
    "#     assert(len(w_tup) == len(b_tup))\n",
    "    \n",
    "#     s_final = np.empty((n_splits ** len(w_tup), ))\n",
    "#     for i in range(len(w_tup)):\n",
    "#         for n in range(n_splits ** i):\n",
    "#             _, s = sample_preimage(w_tup[-(i+1)], b_tup[-(i+1)], z1, n_splits)\n",
    "#             s1 = invert_leaky_relu(s)\n",
    "#             print()\n",
    "    # For the second one, invert leaky_relu\n",
    "    \n",
    "    z1 = invert_leaky_relu(z1)\n",
    "    # Generate first set of preimage points\n",
    "    _, s1 = sample_preimage(w1, b1, z1, n_splits)\n",
    "    \n",
    "    # We have our preimage points, so we can return.\n",
    "    return s1.reshape((s1.shape[0], 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeb5128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dist(v1, v2):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5e1214d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,) (512, 784) (256, 512) (2, 256) (512,) (256,) (2,)\n",
      "6.879941900608678\n"
     ]
    }
   ],
   "source": [
    "encoded_data = torch.load('encoded_data.pt')\n",
    "idx = 51\n",
    "z = encoded_data['mu'][idx].detach().numpy()\n",
    "h1 = encoded_data['h1'][idx].detach().numpy()\n",
    "h2 = encoded_data['h2'][idx].detach().numpy()\n",
    "print(z.shape, w1.shape, w2.shape, w3.shape, b1.shape, b2.shape, b3.shape)\n",
    "x_inv1 = generate_preimage_points(z, w1, w2, w3, b1, b2, b3)\n",
    "x_inv2 = generate_preimage_points_2(h2, w1, w2, b1, b2, n_splits=5, h1=h1)\n",
    "x_inv3 = generate_preimage_points_3(h1, w1, b1, n_splits=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6886500a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 1, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_image(torch.tensor(x_inv1), './inverted_vae_output_t1.png')\n",
    "save_image(torch.tensor(x_inv2), './inverted_vae_output_t2.png')\n",
    "save_image(torch.tensor(x_inv3), './inverted_vae_output_t3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d131e6cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864f7e66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b32257c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf791960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8508a32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac692b88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
